# Model Capability Registry for DeepThinker 2.0
# Updated with current Ollama models (Dec 2025)
#
# Each capability is scored 1-10 (10 = best)
#
# Capabilities:
#   reasoning: Logical reasoning and analysis depth
#   planning: Strategic planning and task decomposition
#   coding: Code generation quality and correctness
#   evaluation: Critical evaluation and assessment
#   creativity: Creative thinking and novel solutions
#   speed: Inference speed (higher = faster)
#   synthesis: Combining multiple inputs into coherent outputs
#   research: Information gathering and synthesis
#   vision: Vision/image understanding (if applicable)
#
# Tiers:
#   reasoning: Best for complex reasoning (gemma3:27b, cogito:14b, devstral)
#   large: High capability (gpt-oss, llava:13b)
#   medium: Balanced capability/speed (gemma3:12b, deepseek-r1:8b, mistral)
#   small: Fast, lower capability (llama3.2, gemma3:4b, qwen3:4b)
#   embedding: Embedding models only

models:
  # ============================================
  # REASONING TIER - Best for complex analysis
  # ============================================
  gemma3:27b:
    reasoning: 9
    planning: 8
    coding: 7
    evaluation: 9
    creativity: 7
    speed: 3
    synthesis: 9
    research: 8
    vram_mb: 17000
    tier: reasoning
    default_temperature: 0.5
    max_tokens: 8192
    
  cogito:14b:
    reasoning: 9
    planning: 8
    coding: 8
    evaluation: 8
    creativity: 7
    speed: 5
    synthesis: 8
    research: 7
    vram_mb: 9000
    tier: reasoning
    default_temperature: 0.5
    max_tokens: 8192
    
  devstral:latest:
    reasoning: 8
    planning: 7
    coding: 9
    evaluation: 7
    creativity: 6
    speed: 5
    synthesis: 7
    research: 7
    vram_mb: 14000
    tier: reasoning
    default_temperature: 0.4
    max_tokens: 8192

  # ============================================
  # LARGE TIER - High capability
  # ============================================
  gpt-oss:latest:
    reasoning: 8
    planning: 8
    coding: 8
    evaluation: 8
    creativity: 8
    speed: 4
    synthesis: 8
    research: 8
    vram_mb: 13000
    tier: large
    default_temperature: 0.5
    max_tokens: 8192
    
  llava:13b:
    reasoning: 7
    planning: 6
    coding: 5
    evaluation: 7
    creativity: 8
    speed: 5
    synthesis: 7
    research: 7
    vision: 9
    vram_mb: 8000
    tier: large
    default_temperature: 0.5
    max_tokens: 4096

  # ============================================
  # MEDIUM TIER - Balanced capability and speed
  # ============================================
  gemma3:12b:
    reasoning: 7
    planning: 6
    coding: 6
    evaluation: 7
    creativity: 6
    speed: 7
    synthesis: 7
    research: 7
    vram_mb: 8100
    tier: medium
    default_temperature: 0.5
    max_tokens: 8192

  deepseek-r1:8b:
    reasoning: 8
    planning: 6
    coding: 9
    evaluation: 7
    creativity: 5
    speed: 8
    synthesis: 6
    research: 6
    vram_mb: 5200
    tier: medium
    default_temperature: 0.3
    max_tokens: 8192

  mistral:instruct:
    reasoning: 7
    planning: 6
    coding: 6
    evaluation: 5
    creativity: 9
    speed: 8
    synthesis: 7
    research: 7
    vram_mb: 4100
    tier: medium
    default_temperature: 0.6
    max_tokens: 8192

  # ============================================
  # SMALL TIER - Fast, for reconnaissance/contraction
  # ============================================
  llama3.2:3b:
    reasoning: 5
    planning: 4
    coding: 5
    evaluation: 5
    creativity: 5
    speed: 9
    synthesis: 5
    research: 5
    vram_mb: 2000
    tier: small
    default_temperature: 0.5
    max_tokens: 4096

  gemma3:4b:
    reasoning: 5
    planning: 4
    coding: 5
    evaluation: 5
    creativity: 5
    speed: 9
    synthesis: 5
    research: 5
    vram_mb: 3300
    tier: small
    default_temperature: 0.5
    max_tokens: 8192
    
  qwen3:4b:
    reasoning: 5
    planning: 4
    coding: 5
    evaluation: 5
    creativity: 5
    speed: 9
    synthesis: 5
    research: 5
    vram_mb: 2500
    tier: small
    default_temperature: 0.5
    max_tokens: 8192

  llama3.2:1b:
    reasoning: 4
    planning: 3
    coding: 4
    evaluation: 4
    creativity: 4
    speed: 10
    synthesis: 4
    research: 4
    vram_mb: 1300
    tier: small
    default_temperature: 0.5
    max_tokens: 4096

  # ============================================
  # EMBEDDING TIER - For embedding/similarity
  # ============================================
  qwen3-embedding:4b:
    embedding: 9
    vram_mb: 2500
    tier: embedding
    default_temperature: 0.0
    max_tokens: 8192
    
  snowflake-arctic-embed:latest:
    embedding: 8
    vram_mb: 670
    tier: embedding
    default_temperature: 0.0
    max_tokens: 512
    
  embeddinggemma:latest:
    embedding: 7
    vram_mb: 621
    tier: embedding
    default_temperature: 0.0
    max_tokens: 512


# ============================================
# ROLE-TO-CAPABILITY MAPPINGS
# Which capabilities matter most for each council type
# ============================================
role_requirements:
  # ExplorerCouncil - fast, broad reconnaissance
  explorer:
    primary: [speed, research]
    secondary: [creativity]
    temperature_range: [0.4, 0.5]
    prefer_tier: small
    
  # EvidenceCouncil - deep, thorough evidence gathering
  evidence:
    primary: [research, reasoning]
    secondary: [evaluation]
    temperature_range: [0.3, 0.4]
    prefer_tier: medium
    
  planner:
    primary: [reasoning, planning]
    secondary: [synthesis]
    temperature_range: [0.5, 0.6]
    prefer_tier: medium
    
  researcher:
    primary: [research, reasoning]
    secondary: [evaluation]
    temperature_range: [0.4, 0.5]
    prefer_tier: medium
    
  coder:
    primary: [coding, reasoning]
    secondary: [evaluation]
    temperature_range: [0.15, 0.25]
    prefer_tier: medium
    
  evaluator:
    primary: [evaluation, reasoning]
    secondary: [synthesis]
    temperature_range: [0.0, 0.1]
    prefer_tier: medium
    
  simulation:
    primary: [creativity, reasoning]
    secondary: [evaluation]
    temperature_range: [0.6, 0.7]
    prefer_tier: medium
    
  synthesis:
    primary: [synthesis, reasoning]
    secondary: [creativity]
    temperature_range: [0.5, 0.6]
    prefer_tier: large
    
  optimist:
    primary: [creativity, reasoning]
    secondary: [synthesis]
    temperature_range: [0.55, 0.65]
    prefer_tier: medium
    
  skeptic:
    primary: [evaluation, reasoning]
    secondary: [research]
    temperature_range: [0.4, 0.5]
    prefer_tier: medium


# ============================================
# PHASE-BASED MODEL SELECTION
# How phases influence model selection
# ============================================
phase_modifiers:
  # Reconnaissance: fast, shallow exploration
  reconnaissance:
    prefer_capabilities: [speed, research]
    prefer_tier: small
    model_count: 2
    max_tokens: 2000
    
  # Analysis: balanced depth and speed
  analysis:
    prefer_capabilities: [reasoning, research]
    prefer_tier: medium
    model_count: 2
    max_tokens: 5000
    
  # Deep Analysis: thorough investigation
  deep_analysis:
    prefer_capabilities: [reasoning, evaluation]
    prefer_tier: reasoning
    model_count: 2
    max_tokens: 8000
    
  # Synthesis: final report generation
  synthesis:
    prefer_capabilities: [synthesis, reasoning]
    prefer_tier: large
    model_count: 1
    use_largest: true
    max_tokens: 10000
    
  # Implementation: code generation
  implementation:
    prefer_capabilities: [coding, reasoning]
    prefer_tier: medium
    model_count: 2
    max_tokens: 15000
    
  # Simulation: scenario exploration
  simulation:
    prefer_capabilities: [creativity, reasoning]
    prefer_tier: medium
    model_count: 2
    max_tokens: 6000


# ============================================
# TIER GROUPINGS (for quick selection)
# ============================================
tier_groups:
  reasoning:
    - gemma3:27b
    - cogito:14b
    - devstral:latest
    
  large:
    - gemma3:27b
    - gpt-oss:latest
    - cogito:14b
    - llava:13b
    
  medium:
    - gemma3:12b
    - deepseek-r1:8b
    - mistral:instruct
    - devstral:latest
    
  small:
    - llama3.2:3b
    - gemma3:4b
    - qwen3:4b
    - llama3.2:1b
    
  embedding:
    - qwen3-embedding:4b
    - snowflake-arctic-embed:latest
    - embeddinggemma:latest
